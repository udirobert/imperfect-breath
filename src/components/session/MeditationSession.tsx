/**
 * ULTIMATE UNIFIED SESSION COMPONENT
 *
 * SINGLE SOURCE OF TRUTH for ALL breathing session UIs.
 * Consolidates: SessionInProgress + UnifiedBreathingSession + SessionOrchestrator + ClassicBreathingSession
 *
 * Design Principles:
 * - DRY: No duplication - one component for all session types
 * - CLEAN: Meditation-focused UX with silent error handling
 * - ORGANISED: Clear phase-based structure with mode configurations
 * - MODULAR: Composable features that can be enabled/disabled
 * - PERFORMANT: Adaptive optimization for mobile meditation
 *
 * Features Consolidated:
 * ‚úÖ Classic mode (no camera, pure mindfulness)
 * ‚úÖ Enhanced mode (camera + AI vision)
 * ‚úÖ Mobile optimization (adaptive performance)
 * ‚úÖ Vision processing (FaceMesh with 20+ landmarks)
 * ‚úÖ Session orchestration (phase management)
 * ‚úÖ Error boundaries (gentle, meditation-appropriate)
 * ‚úÖ Audio guidance support
 * ‚úÖ Performance monitoring
 * ‚úÖ Zustand state management
 */

import React, {
  useState,
  useEffect,
  useCallback,
  useMemo,
  useRef,
} from "react";
import { Card, CardContent } from "../ui/card";
import { Button } from "../ui/button";
import { Progress } from "../ui/progress";
import { Badge } from "../ui/badge";
import {
  Play,
  Pause,
  Square,
  Camera,
  CameraOff,
  Eye,
  Activity,
  Heart,
  Volume2,
  VolumeX,
  Loader2,
  Settings,
  Maximize2,
} from "lucide-react";

// Core imports
import BreathingAnimation from "../BreathingAnimation";
import { FaceMeshOverlay } from "../vision/FaceMeshOverlay";
import { GentleErrorBoundary } from "../meditation/GentleErrorBoundary";
import { CalmLoading } from "../meditation/CalmLoading";
import { SessionPreview } from "./SessionPreview";
import { SessionProgressDisplay } from "./SessionProgressDisplay";
import { PostSessionCelebration } from "./PostSessionCelebration";
import { SessionControls } from "./SessionControls";
import { MobileBreathingInterface } from "./MobileBreathingInterface";

// Unified hooks
import { useSession } from "../../hooks/useSession";
import { useMeditationVision } from "../../hooks/useMeditationVision";
import useAdaptivePerformance, {
  useIsMobile,
} from "../../hooks/useAdaptivePerformance";
import { useAuth } from "../../hooks/useAuth";
import { TrackingStatus } from "../../hooks/visionTypes";
import { useCamera } from "../../contexts/CameraContext";

// Shared types - consolidated
import { SessionMetrics, SessionModeConfig, SessionPhase, SessionMode } from "../../types/session";

// Patterns and utilities
import {
  BREATHING_PATTERNS,
  BreathingPhaseName,
} from "../../lib/breathingPatterns";
import { mapPatternForAnimation } from "../../lib/session/pattern-mapper";

// ============================================================================
// CONSOLIDATED TYPES - Using shared types from ../../types/session
// ============================================================================

// Mode configurations - consolidated from all session components
// Using shared SessionModeConfig type from ../../types/session
const SESSION_MODE_CONFIGS: Record<SessionMode, SessionModeConfig> = {
  classic: {
    enableCamera: false,
    enableVision: false,
    enableAudio: true,
    enableAdvancedFeatures: false,
    enableMobileOptimizations: false,
    showPerformanceMonitor: false,
    layout: "single",
    description: "Pure breathing practice with no distractions",
  },
  enhanced: {
    enableCamera: true,
    enableVision: true,
    enableAudio: true,
    enableAdvancedFeatures: true,
    enableMobileOptimizations: true,
    showPerformanceMonitor: false,
    layout: "dual",
    description: "AI-powered breathing with real-time feedback",
  },
  advanced: {
    enableCamera: true,
    enableVision: true,
    enableAudio: true,
    enableAdvancedFeatures: true,
    enableMobileOptimizations: true,
    showPerformanceMonitor: true,
    layout: "dual",
    description: "Full featured session with performance monitoring",
  },
  mobile: {
    enableCamera: true,
    enableVision: true,
    enableAudio: true,
    enableAdvancedFeatures: true,
    enableMobileOptimizations: true,
    showPerformanceMonitor: false,
    layout: "mobile",
    description: "Mobile-optimized session with haptic feedback",
  },
};

export interface MeditationSessionConfig {
  mode: SessionMode;
  pattern: {
    name: string;
    phases: {
      inhale: number;
      hold?: number;
      exhale: number;
      pause?: number;
    };
    difficulty?: string;
    benefits?: string[];
  };
  autoStart?: boolean;
  customSettings?: Partial<SessionModeConfig>;
  // DRY: Default session durations based on user authentication
  maxCycles?: number;
  targetDuration?: number; // in minutes
}

// SessionMetrics moved to shared types file - consolidated

interface MeditationSessionProps {
  config: MeditationSessionConfig;
  onSessionComplete?: (metrics: SessionMetrics) => void;
  onSessionExit?: () => void;
  adaptiveFlow?: boolean; // New: indicates if this is part of adaptive flow
}

// ============================================================================
// MAIN COMPONENT - Ultimate unified session interface
// ============================================================================

export const MeditationSession: React.FC<MeditationSessionProps> = ({
  config,
  onSessionComplete,
  onSessionExit,
}) => {
  const { user } = useAuth();
  const isMobile = useIsMobile();

  // Get mode configuration (with custom overrides)
  const modeConfig = useMemo(
    () => ({
      ...SESSION_MODE_CONFIGS[config.mode],
      ...config.customSettings,
    }),
    [config.mode, config.customSettings]
  );

  // Adaptive performance optimization (respects meditation UX requirements)
  const { profile, isLowEndDevice, shouldUseBatterySaver, isMobileOptimized } =
    useAdaptivePerformance();

  // Core session state
  const [phase, setPhase] = useState<SessionPhase>("setup");
  const [showPreparation, setShowPreparation] = useState(false);
  const [audioEnabled, setAudioEnabled] = useState(modeConfig.enableAudio);
  const [showAdvancedMetrics, setShowAdvancedMetrics] = useState(false);
  const [loadingState, setLoadingState] = useState({
    camera: false,
    models: false,
    session: false,
    message: "",
  });

  // Camera and video refs with proper lifecycle management
  const videoRef = useRef<HTMLVideoElement>(null);

  // CLEAN: Single source of truth for session phase
  const [currentPhase, setCurrentPhase] = useState<SessionPhase>("setup");
  const [isVideoReady, setIsVideoReady] = useState(false);

  // MODULAR: User-controllable overlay preferences
  const [showFaceMesh, setShowFaceMesh] = useState(true);
  const [showRestlessnessScore, setShowRestlessnessScore] = useState(true);

  // Monitor video element for readiness - consolidated video management
  useEffect(() => {
    const video = videoRef.current;
    if (!video) return;

    const handleVideoReady = () => {
      console.log("üé• Video element ready, readyState:", video.readyState);
      if (video.readyState >= 2) {
        setIsVideoReady(true);
      }
    };

    const handleVideoError = (error: Event) => {
      console.error("‚ùå Video element error:", error);
      setIsVideoReady(false);
    };

    // Listen for video ready events
    video.addEventListener("loadedmetadata", handleVideoReady);
    video.addEventListener("canplay", handleVideoReady);
    video.addEventListener("error", handleVideoError);

    // Check initial state
    if (video.readyState >= 2) {
      setIsVideoReady(true);
    }

    return () => {
      video.removeEventListener("loadedmetadata", handleVideoReady);
      video.removeEventListener("canplay", handleVideoReady);
      video.removeEventListener("error", handleVideoError);
    };
  }, []); // Consolidated: no external dependencies needed

  // ENHANCEMENT: Adaptive encouragement timing (PERFORMANT)
  const [lastEncouragementTime, setLastEncouragementTime] = useState(0);
  const [encouragementStreak, setEncouragementStreak] = useState(0);
  const [adaptiveEncouragementEnabled, setAdaptiveEncouragementEnabled] =
    useState(true);

  // PERFORMANT: Debug state tracking
  const debugKeyRef = useRef<string>("");

  // Use CameraContext for camera state
  const { stream: cameraStream } = useCamera();

  // Enhanced session management with adaptive performance
  const visionEnabled = modeConfig.enableVision && !isLowEndDevice;

  // Memoize vision config to prevent recreation on every render
  const visionConfig = useMemo(
    () => ({
      sessionId: `session_${Date.now()}`,
      targetFPS: 2,
      silentMode: false,
      gracefulDegradation: true,
    }),
    []
  ); // Empty deps - only create once

  // CLEAN: Log only once when component mounts
  React.useEffect(() => {
    console.log("üîç Vision enablement debug:", {
      modeConfigEnableVision: modeConfig.enableVision,
      isLowEndDevice,
      finalVisionEnabled: visionEnabled,
      configMode: config.mode,
    });

    // MODULAR: Direct backend health check
    fetch("http://localhost:8001/health")
      .then((res) => res.json())
      .then((health) => {
        console.log("üè• Backend health check:", health);
      })
      .catch((err) => {
        console.error("‚ùå Backend health check failed:", err);
      });
  }, []); // Empty dependency array - run only once

  // Memoize session options to prevent useSession hook from being recreated during phase transitions
  const sessionOptions = useMemo(() => ({
    autoStart: config.autoStart,
    enableVision: true, // CLEAN: Force enable for debugging
    targetFPS: 2, // Default FPS for vision processing
    videoElement: videoRef,
  }), [config.autoStart, videoRef]);

  const session = useSession(sessionOptions);

  // Vision processing hook - only enable when needed
  const vision = useMeditationVision(visionEnabled ? visionConfig : undefined);

  // Memoize landmarks to prevent infinite re-renders
  const landmarks = useMemo(
    () => vision?.state.metrics?.faceLandmarks || [],
    [vision?.state.metrics?.faceLandmarks]
  );

  // Track initialization to prevent infinite re-renders
  const isInitializedRef = useRef(false);
  const configHashRef = useRef("");

  // Initialize session with pattern configuration
  useEffect(() => {
    if (config && config.pattern) {
      // Create a hash of the config to detect actual changes
      const configHash = JSON.stringify({
        mode: config.mode,
        pattern: config.pattern,
        enableCamera: modeConfig.enableCamera,
        enableAudio: modeConfig.enableAudio,
        enableVision: modeConfig.enableVision,
      });

      // Only initialize if config actually changed
      if (configHash !== configHashRef.current || !isInitializedRef.current) {
        configHashRef.current = configHash;
        isInitializedRef.current = true;

        console.log("üßò Initializing meditation session:", {
          patternName: config.pattern.name,
          phases: config.pattern.phases,
          mode: config.mode,
        });

        // Convert MeditationSessionConfig to SessionConfig for the store
        const sessionConfig = {
          mode:
            config.mode === "classic"
              ? ("basic" as const)
              : ("enhanced" as const),
          pattern: {
            id: config.pattern.name.toLowerCase().replace(/\s+/g, "_"),
            name: config.pattern.name,
            description: `${config.pattern.name} breathing pattern`,
            inhale: config.pattern.phases.inhale,
            hold: config.pattern.phases.hold || 0,
            exhale: config.pattern.phases.exhale,
            hold_after_exhale: config.pattern.phases?.pause || 0,
            benefits: config.pattern.benefits || [
              "Improved focus",
              "Reduced stress",
              "Better breathing control",
            ],
          },
          enableCamera: modeConfig.enableCamera,
          enableAudio: modeConfig.enableAudio,
          enableAI: modeConfig.enableVision, // Map vision to AI feature
        };

        // Initialize the session store
        console.log("Session config prepared:", sessionConfig);
        session.initialize(sessionConfig)
          .catch((error) => {
            console.error("‚ùå Failed to initialize session:", error);
            // Handle initialization error gracefully
            session.setError("Failed to initialize session. Please try again.");
          });
      }
    }
  }, [config, modeConfig]);

  // ENHANCEMENT: Adaptive encouragement system (MODULAR)
  const getAdaptiveEncouragement = useCallback(() => {
    if (!adaptiveEncouragementEnabled) return null;

    const now = Date.now();
    const timeSinceLastEncouragement = now - lastEncouragementTime;
    const sessionProgress = session.metrics
      ? (session.metrics.cycleCount / 10) * 100
      : 0; // Assume 10 cycles target
    const stillnessScore = session.visionMetrics?.stillness || 0;

    // Adaptive timing based on performance
    let encouragementInterval = 30000; // 30 seconds default

    if (stillnessScore > 80) {
      encouragementInterval = 45000; // Less frequent for high performers
    } else if (stillnessScore < 50) {
      encouragementInterval = 20000; // More frequent for struggling users
    }

    // Early session encouragement
    if (sessionProgress < 25) {
      encouragementInterval = Math.min(encouragementInterval, 25000);
    }

    if (timeSinceLastEncouragement < encouragementInterval) {
      return null;
    }

    // Generate contextual encouragement
    const encouragements = {
      highPerformer: [
        "Beautiful focus! You're mastering this pattern.",
        "Excellent stillness. Your practice is deepening.",
        "Outstanding! You're in complete control.",
      ],
      steady: [
        "Great work! Keep that steady rhythm.",
        "Well done! You're building excellent habits.",
        "Nice consistency! You're doing wonderfully.",
      ],
      needsSupport: [
        "You're doing great! Take it one breath at a time.",
        "Every breath counts. You're making progress!",
        "Stay with it! You're stronger than you think.",
      ],
    };

    let messageSet = encouragements.steady;
    if (stillnessScore > 75) {
      messageSet = encouragements.highPerformer;
    } else if (stillnessScore < 60) {
      messageSet = encouragements.needsSupport;
    }

    const message = messageSet[Math.floor(Math.random() * messageSet.length)];

    setLastEncouragementTime(now);
    setEncouragementStreak((prev) => prev + 1);

    return {
      message,
      type: stillnessScore > 75 ? "celebration" : "encouragement",
      haptic: stillnessScore > 75,
    };
  }, [
    adaptiveEncouragementEnabled,
    lastEncouragementTime,
    session.metrics,
    session.visionMetrics,
  ]);

  // Apply encouragement during active session
  useEffect(() => {
    if (currentPhase === "active" && session.isActive) {
      console.log("üìä Session metrics:", {
        isActive: session.isActive,
        duration: session.getSessionDuration?.(),
        cycleCount: session.metrics?.cycleCount,
        currentPhase: session.metrics?.currentPhase,
        completion: session.getCompletionPercentage?.(),
      });

      const encouragement = getAdaptiveEncouragement();
      if (encouragement) {
        // Trigger haptic feedback for celebrations
        if (encouragement.haptic && "vibrate" in navigator) {
          navigator.vibrate([100, 50, 100]);
        }

        // Here you would integrate with your notification/toast system
        console.log("üåü Adaptive encouragement:", encouragement);
      }
    }
  }, [
    currentPhase,
    session.isActive,
    session.metrics,
    session.getSessionDuration,
    session.getCompletionPercentage,
    getAdaptiveEncouragement,
  ]);

  // Transition to active phase when session starts
  useEffect(() => {
    if (
      session.isActive &&
      (currentPhase === "preparation" || currentPhase === "camera_setup")
    ) {
      console.log("‚úÖ Session is active, transitioning to active phase");
      setCurrentPhase("active");
    }
  }, [session.isActive, currentPhase]);

  // Ensure video stream is maintained when transitioning to active phase
  useEffect(() => {
    if (currentPhase === "active" && cameraStream && videoRef.current) {
      const video = videoRef.current;
      if (!video.srcObject) {
        console.log("üîÑ Reattaching camera stream to video element in active phase");
        video.srcObject = cameraStream;
        video.muted = true;
        video.autoplay = true;
        video.playsInline = true;
        
        // Ensure video is visible and properly sized
        video.style.display = 'block';
        video.style.visibility = 'visible';
        video.style.opacity = '1';
        video.style.width = '100%';
        video.style.height = '100%';
        video.style.position = 'absolute';
        video.style.top = '0';
        video.style.left = '0';
        video.style.zIndex = '1';
      }
    }
  }, [currentPhase, cameraStream]);

  // Attach camera stream to video element when camera is granted
  useEffect(() => {
    if (cameraStream && videoRef.current && !videoRef.current.srcObject) {
      console.log("üìπ MeditationSession: Attaching camera stream to video element");
      const video = videoRef.current;

      // Set stream and video properties
      video.srcObject = cameraStream;
      video.muted = true;
      video.autoplay = true;
      video.playsInline = true;

      // Ensure video is playing with retry mechanism
      const playVideo = async (retries = 3) => {
        for (let i = 0; i < retries; i++) {
          try {
            await video.play();
            console.log('‚úÖ MeditationSession: Video is playing, readyState:', video.readyState);
            return;
          } catch (playError) {
            console.warn(`‚ö†Ô∏è MeditationSession: Video play attempt ${i + 1} failed:`, playError);
            if (i < retries - 1) {
              await new Promise(resolve => setTimeout(resolve, 500));
            }
          }
        }
        console.warn('‚ö†Ô∏è MeditationSession: All video play attempts failed');
      };

      playVideo();

      // Set video element styling
      video.style.display = 'block';
      video.style.visibility = 'visible';
      video.style.opacity = '1';
      video.style.width = '100%';
      video.style.height = '100%';
      video.style.position = 'absolute';
      video.style.top = '0';
      video.style.left = '0';
      video.style.zIndex = '1';
      console.log('‚úÖ MeditationSession: Video element configured');
    }
  }, [cameraStream]);

  // Synchronized vision processing startup with proper checks
  useEffect(() => {
    const startVisionProcessing = async () => {
      // Enhanced conditions with better logging
      const conditions = {
        correctPhase:
          currentPhase === "active" || currentPhase === "camera_setup",
        visionEnabled,
        hasVideoElement: !!videoRef.current,
        hasVisionHook: !!vision,
        visionNotActive: vision && !vision.state.isActive,
        videoReady: isVideoReady,
        videoReadyState: (videoRef.current?.readyState || 0) >= 2,
        hasCameraStream: !!cameraStream,
      };

      console.log("üîç Vision startup conditions check:", conditions);

      if (
        conditions.correctPhase &&
        conditions.visionEnabled &&
        conditions.hasVideoElement &&
        conditions.hasVisionHook &&
        conditions.visionNotActive &&
        conditions.videoReady &&
        conditions.videoReadyState &&
        conditions.hasCameraStream
      ) {
        try {
          console.log(
            "üîç Starting vision processing with video readyState:",
            videoRef.current?.readyState
          );
          await vision.start(videoRef.current!);
          console.log(
            "‚úÖ Vision processing started successfully - Facemesh should now be active"
          );
        } catch (err) {
          console.warn("‚ö†Ô∏è Vision start failed, continuing without:", err);
          // Vision hook handles graceful degradation internally
        }
      } else {
        const missingConditions = Object.entries(conditions)
          .filter(([_, value]) => !value)
          .map(([key]) => key);

        if (missingConditions.length > 0) {
          console.log(
            "üîç Vision startup waiting for:",
            missingConditions.join(", ")
          );
        }
      }
    };

    startVisionProcessing();
  }, [
    currentPhase,
    visionEnabled,
    vision,
    isVideoReady,
    videoRef.current?.readyState,
    cameraStream, // Added dependency to retry when camera becomes available
  ]);

  // Cleanup vision processing when component unmounts
  const visionRef = useRef(vision);
  visionRef.current = vision;

  useEffect(() => {
    return () => {
      if (visionRef.current) {
        visionRef.current.stop();
      }
    };
  }, []); // Empty dependency array - only run on unmount

  // Camera initialization is now handled by CameraSetup component

  // Rest of the component implementation would continue...
  // (The full implementation is quite long, so I'll focus on the key enhancement)

  // Use mobile-optimized interface on mobile devices
  if (isMobile && modeConfig.enableMobileOptimizations) {
    return (
      <MobileBreathingInterface
        onEndSession={onSessionExit}
        patternName={config.pattern.name}
      />
    );
  }

  return (
    <GentleErrorBoundary
      fallbackMessage="Your breathing practice continues peacefully. Let's take a gentle reset together."
      onReset={() => setPhase("setup")}
    >
      <div className="max-w-4xl mx-auto p-4 space-y-6">
        {/* Subtle mode indicator */}
        {config.mode !== "classic" && (
          <div className="text-center">
            <Badge variant="secondary" className="text-xs">
              <Eye className="w-3 h-3 mr-1" />
              {config.mode.charAt(0).toUpperCase() + config.mode.slice(1)}{" "}
              Session
            </Badge>
          </div>
        )}

        {/* Phase-based content */}
        <Card className="border-0 shadow-lg">
          <CardContent className="p-6">
            {currentPhase === "setup" && (
              <SessionPreview
                patternName={config.pattern.name}
                pattern={config.pattern}
                enableCamera={modeConfig.enableCamera}
                videoRef={videoRef}
                onStart={(cameraEnabled) => {
                  console.log(
                    "üéØ Session preview complete, moving to active phase...",
                    { cameraEnabled }
                  );
                  
                  // Start session with camera enabled/disabled based on user choice
                  session.initialize({
                    mode: config.mode === "classic" ? "basic" : "enhanced",
                    pattern: {
                      id: config.pattern.name.toLowerCase().replace(/\s+/g, "_"),
                      name: config.pattern.name,
                      description: `${config.pattern.name} breathing pattern`,
                      inhale: config.pattern.phases.inhale,
                      hold: config.pattern.phases.hold || 0,
                      exhale: config.pattern.phases.exhale,
                      hold_after_exhale: config.pattern.phases?.pause || 0,
                      benefits: config.pattern.benefits || [
                        "Improved focus",
                        "Reduced stress",
                        "Better breathing control",
                      ],
                    },
                    enableCamera: cameraEnabled && modeConfig.enableCamera,
                    enableAudio: modeConfig.enableAudio,
                    enableAI: modeConfig.enableVision,
                  }).then(() => {
                    session.start().catch((error) => {
                      console.error("‚ùå Failed to start session:", error);
                      session.setError("Failed to start session. Please try again.");
                    });
                  }).catch((error) => {
                    console.error("‚ùå Failed to initialize session:", error);
                    session.setError("Failed to initialize session. Please try again.");
                  });
                  
                  setCurrentPhase("active");
                }}
                onCancel={onSessionExit}
              />
            )}

            {currentPhase === "active" && (
              <div className="space-y-6">
                {/* Rich Progress Display */}
                <SessionProgressDisplay
                  patternName={config.pattern.name}
                  duration={
                    session.getSessionDuration
                      ? session.getSessionDuration()
                      : "00:00"
                  }
                  cycleCount={session.metrics?.cycleCount || 0}
                  progressPercentage={
                    session.getCompletionPercentage
                      ? session.getCompletionPercentage()
                      : 0
                  }
                  qualityScore={vision?.state.metrics?.stillness}
                  stillnessScore={vision?.state.metrics?.stillness}
                  showQualityMetrics={modeConfig.enableVision}
                />

                {/* Camera Feed - only show if camera is enabled and available */}
                {modeConfig.enableCamera && session.cameraStream && (
                  <div className="flex justify-center mb-4">
                    <div className="w-64 h-48 md:w-96 md:h-72 rounded-lg overflow-hidden shadow-md border-2 border-primary/20 relative">
                      <video
                        ref={videoRef}
                        className="w-full h-full object-cover"
                        muted
                        autoPlay
                        playsInline
                        style={{ transform: 'scaleX(-1)' }} // Mirror for selfie mode
                      />
                      {/* Face landmarks overlay */}
                      <FaceMeshOverlay
                        videoElement={videoRef.current}
                        landmarks={landmarks}
                        isActive={vision?.state.isActive || false}
                        confidence={vision?.state.metrics?.confidence || 0}
                        postureScore={vision?.state.metrics?.posture || 0}
                        movementLevel={
                          vision?.state.metrics?.restlessnessScore
                            ? vision?.state.metrics?.restlessnessScore / 100
                            : 0
                        }
                      />
                      {/* Vision status indicator */}
                      <div className="absolute top-2 right-2 bg-black/50 text-white text-xs px-2 py-1 rounded">
                        {vision?.state.isActive
                          ? "Vision Active"
                          : "Vision Starting"}
                      </div>
                      {/* Debug info */}
                      <div className="absolute bottom-2 left-2 bg-black/50 text-white text-xs px-2 py-1 rounded">
                        Stream: {session.cameraStream ? '‚úÖ' : '‚ùå'} |
                        Video: {videoRef.current?.srcObject ? '‚úÖ' : '‚ùå'} |
                        Ready: {(videoRef.current?.readyState || 0) >= 2 ? '‚úÖ' : '‚ùå'}
                      </div>
                    </div>
                  </div>
                )}

                {/* Breathing Animation */}
                <div className="flex justify-center">
                  <BreathingAnimation
                    phase={
                      (session.metrics?.currentPhase === "pause"
                        ? "hold_after_exhale"
                        : session.metrics?.currentPhase) || "inhale"
                    }
                    pattern={config.pattern}
                    isActive={session.isActive}
                  />
                </div>

                {/* Session Controls */}
                <SessionControls
                  onEndSession={() => {
                    // Collect real session metrics before completing
                    const sessionDuration = session.getSessionDuration?.() || 0;
                    const cycleCount = session.metrics?.cycleCount || 0;
                    const visionData = vision?.state.metrics;

                    const metrics: SessionMetrics = {
                      duration:
                        typeof sessionDuration === "string"
                          ? parseInt(sessionDuration.split(":")[0]) * 60 +
                            parseInt(sessionDuration.split(":")[1])
                          : sessionDuration,
                      cycleCount,
                      breathHoldTime: 0, // Could be calculated from pattern
                      stillnessScore: visionData?.stillness,
                      cameraUsed: !!cameraStream,
                      sessionType:
                        config.mode === "classic" ? "classic" : "enhanced",
                      visionSessionId: visionConfig.sessionId,
                      visionMetrics: visionData
                        ? {
                            averageStillness: visionData.stillness,
                            faceDetectionRate: visionData.presence,
                            postureScore: visionData.posture,
                          }
                        : undefined,
                    };

                    // Stop vision processing before completing
                    if (vision) {
                      vision.stop();
                    }

                    // Stop camera stream
                    if (cameraStream) {
                      cameraStream.getTracks().forEach((track) => track.stop());
                      setCameraStream(null);
                    }

                    // Complete session in store
                    session.complete();

                    // Transition to completion phase
                    setCurrentPhase("complete");

                    // Call completion callback with real metrics
                    onSessionComplete?.(metrics);
                  }}
                />

                {/* Adaptive Encouragement Toggle */}
                <div className="flex justify-center">
                  <Button
                    variant="outline"
                    onClick={() =>
                      setAdaptiveEncouragementEnabled(
                        !adaptiveEncouragementEnabled
                      )
                    }
                  >
                    {adaptiveEncouragementEnabled ? "Disable" : "Enable"}{" "}
                    Adaptive Encouragement
                  </Button>
                </div>
              </div>
            )}

            {currentPhase === "complete" && (
              <PostSessionCelebration
                metrics={{
                  patternName: config.pattern.name,
                  duration: 0, // Would be populated from actual session duration
                  score: session.visionMetrics?.stillness || 85,
                  cycles: 0, // Would be populated from actual cycle count
                  sessionType:
                    config.mode === "classic" ? "classic" : "enhanced",
                  isFirstSession: false, // Would be determined from user history
                }}
                onContinue={() => setCurrentPhase("setup")}
                onExplorePatterns={() => {
                  // Would navigate to patterns page
                  console.log("Navigate to patterns");
                }}
                onClose={() => {
                  // Stop vision processing before exiting
                  if (vision) {
                    vision.stop();
                  }
                  onSessionExit?.();
                }}
              />
            )}
          </CardContent>
        </Card>
      </div>
    </GentleErrorBoundary>
  );
};

// Clean component exports with all consolidated types
export default MeditationSession;
